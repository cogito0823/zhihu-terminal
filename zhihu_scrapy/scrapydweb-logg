nohup: ignoring input
[2020-05-17 05:59:51,268] INFO     in apscheduler.scheduler: Scheduler started
[2020-05-17 05:59:51,297] INFO     in scrapydweb.run: ScrapydWeb version: 1.4.0
[2020-05-17 05:59:51,298] INFO     in scrapydweb.run: Use 'scrapydweb -h' to get help
[2020-05-17 05:59:51,299] INFO     in scrapydweb.run: Main pid: 658
[2020-05-17 05:59:51,300] DEBUG    in scrapydweb.run: Loading default settings from /root/anaconda3/lib/python3.7/site-packages/scrapydweb/default_settings.py
[2020-05-17 05:59:51,466] DEBUG    in scrapydweb.run: Reading settings from command line: Namespace(bind='0.0.0.0', debug=False, disable_auth=False, disable_logparser=False, disable_monitor=False, port=5000, scrapyd_server=None, switch_scheduler_state=False, verbose=False)
[2020-05-17 05:59:51,467] DEBUG    in scrapydweb.utils.check_app_config: Checking app config
[2020-05-17 05:59:51,472] INFO     in scrapydweb.utils.check_app_config: Basic auth enabled with USERNAME/PASSWORD: 'cogito'/'asd745699887'
[2020-05-17 05:59:51,476] INFO     in scrapydweb.utils.check_app_config: Setting up URL_SCRAPYDWEB: http://127.0.0.1:5000
[2020-05-17 05:59:51,476] INFO     in scrapydweb.utils.check_app_config: Setting up SCRAPY_PROJECTS_DIR: /root/zhihu-terminal/zhihu_scrapy
[2020-05-17 05:59:51,477] DEBUG    in scrapydweb.utils.check_app_config: Checking connectivity of SCRAPYD_SERVERS...
[2020-05-17 05:59:51,487] ERROR    in scrapydweb.utils.check_app_config: HTTPConnectionPool(host='localhost', port=6801): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7efea82e33d0>: Failed to establish a new connection: [Errno 111] Connection refused'))
/root/anaconda3/lib/python3.7/site-packages/sqlalchemy/ext/declarative/clsregistry.py:129: SAWarning: This declarative base already contains a class with the same class name and module name as scrapydweb.models.Job, and will be replaced in the string-lookup table.
  % (item.__module__, item.__name__)
[2020-05-17 05:59:51,596] DEBUG    in scrapydweb.utils.check_app_config: Created 2 tables for JobsView
[2020-05-17 05:59:51,598] INFO     in scrapydweb.utils.check_app_config: Setting up LOCAL_SCRAPYD_LOGS_DIR: /root/zhihu-terminal/zhihu_scrapy/logs
[2020-05-17 05:59:51,598] INFO     in scrapydweb.utils.check_app_config: Setting up LOCAL_SCRAPYD_SERVER: 0.0.0.0:6800
[2020-05-17 05:59:51,599] ERROR    in scrapydweb.run: Check app config fail: 

****************************************************************************************************
Overriding custom settings from /root/zhihu-terminal/zhihu_scrapy/scrapydweb_settings_v10.py
****************************************************************************************************


Index Group                Scrapyd IP:Port       Connectivity Auth
####################################################################################################
1____ None________________ 129.204.67.49:6800____ True_______ None
2____ group_______________ localhost:6801________ False______ ('username', 'password')
####################################################################################################


LOCAL_SCRAPYD_SERVER '0.0.0.0:6800' is not in the Scrapyd servers you have added:
['129.204.67.49:6800', 'localhost:6801']
Check and update your settings in /root/zhihu-terminal/zhihu_scrapy/scrapydweb_settings_v10.py

